{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Developing, Training, and Deploying a TensorFlow model on Google Cloud Platform</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-notebook')\n",
    "sns.set()\n",
    "\n",
    "import datalab.storage as storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up Cloud Environment on your GCP Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change to your bucket and project name, to set up environment in your project, store files in your bucket and to run the model on cloud ml engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure you put the correct values here !!!\n",
    "BUCKET='usc-demo'         #Change it based on the name of your GCS Bucket\n",
    "PROJECT='usc-demo-class'  #Change it to your Project Name\n",
    "REGION='us-west1'         #Look at the Region mentioned in details of the Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select the data file, date and the target variables that you want to use for the revenue forecast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file='data.csv'    #Name of the data File\n",
    "date='date_of_sale'\n",
    "target='net_sales'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file, parse_dates=[date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.upc == 25097000000]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upc_code = data.upc[0]\n",
    "departmentname = data.departmentname[0]\n",
    "print(upc_code,departmentname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[date, target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index(data[date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = [date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[\"net_sales\"].resample(\"D\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(data):\n",
    "    data_np = data.values\n",
    "    train = []\n",
    "    for i in range(90, len(data_np)):\n",
    "        train.append(data_np[i-90:i])\n",
    "        \n",
    "    list_zero = train[0]\n",
    "    df = pd.DataFrame(list_zero).T\n",
    "    \n",
    "    for i in range(1, len(train)):\n",
    "        a = train[i]\n",
    "        b = pd.DataFrame(a).T\n",
    "        b.index = [i]\n",
    "        df = pd.concat((df, b), axis = 0)\n",
    "        \n",
    "    ind = int(0.8*len(df))\n",
    "    train = df[:ind]\n",
    "    eval_ = df[ind:]\n",
    "    test = eval_.iloc[-1]\n",
    "    test = test[30:]\n",
    "    \n",
    "    \n",
    "    last_date = data[-30:-29]\n",
    "    last_date = last_date.index\n",
    "    \n",
    "    dates = []\n",
    "    for i in range(0, 60):\n",
    "        temp = last_date + timedelta(days = 1)\n",
    "        dates.append(last_date)\n",
    "        last_date = temp\n",
    "    dates = pd.DataFrame(dates)\n",
    "    \n",
    "    return train, eval_, test, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, eval_, test, dates = data_prep(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"train.csv\", index = False, header = False)\n",
    "eval_.to_csv(\"eval.csv\", index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.Bucket(BUCKET).item('data/train.csv').write_to(train.to_csv(index=False, header=False),'text/csv')\n",
    "storage.Bucket(BUCKET).item('data/eval.csv').write_to(eval_.to_csv(index=False, header=False),'text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf cnnmodel\n",
    "python -m trainer.task \\\n",
    "  --train_data_paths=gs://${BUCKET}/data/train.csv \\\n",
    "  --eval_data_paths=gs://${BUCKET}/data/eval.csv \\\n",
    "  --output_dir=cnnmodel \\\n",
    "  --job-dir=./tmp \\\n",
    "  --train_steps=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train in Cloud ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "SEQ_LEN=90\n",
    "gsutil rm -r gs://${BUCKET}/out/trained\n",
    "JOBNAME=uscdemo_$(date -u +%y%m%d_%H%M%S)\n",
    "gcloud ai-platform jobs submit training $JOBNAME \\\n",
    "  --job-dir=gs://${BUCKET}/out/trained \\\n",
    "  --package-path=${PWD}/trainer \\\n",
    "  --module-name=trainer.task \\\n",
    "  --region=us-west1 \\\n",
    "  --runtime-version=1.8 \\\n",
    "  --scale-tier=BASIC \\\n",
    "  -- \\\n",
    "  --train_data_paths=gs://${BUCKET}/data/train.csv \\\n",
    "  --eval_data_paths=gs://${BUCKET}/data/eval.csv  \\\n",
    "  --output_dir=gs://${BUCKET}/out/trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run below lines to see the Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#gcloud ai-platform jobs describe demandml_190523_151932_v19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create and Delploy the trained job on model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run it only after your Job has completed running**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "REGION='us-west1'\n",
    "MODEL_NAME=revenueml_$(date -u +%y%m%d_%H%M%S)\n",
    "MODEL_VERSION=\"v1\"\n",
    "gcloud ml-engine models create $MODEL_NAME\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/out/trained/export/exporter/ | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "\n",
    "gcloud ai-platform versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version 1.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THE MODEL IS DEPLOYED .... YAYYY !!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud ML Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You might see some errors after running it, but as long as your model is deployed, you can ignore them*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import json\n",
    "\n",
    "MODEL_NAME = 'revenueml_190711_212322'  #Change the Model name here, Put the name of your Model !!!\n",
    "print(MODEL_NAME)\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "api = discovery.build('ml', 'v1', credentials=credentials)\n",
    "\n",
    "test = test\n",
    "request_data = {\"instances\": [test]}\n",
    "\n",
    " \n",
    "parent = 'projects/%s/models/%s/versions/%s' % (PROJECT,MODEL_NAME, 'v1')\n",
    "response = api.projects().predict(body = request_data, name = parent).execute()\n",
    "#print \"response={0}\".format(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Predictions using ML Model on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = response[\"predictions\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictlist=[] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in a[0].items():\n",
    "    temp = [key,value]\n",
    "    dictlist.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = data[-30:]\n",
    "predicted = pd.DataFrame(predicted)\n",
    "predicted.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dictlist[0]\n",
    "a = a[1]\n",
    "a = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = (date,predicted,a)\n",
    "result = pd.concat((dates,predicted,a), axis = 1)\n",
    "result.columns = [\"DATE\", \"ACTUAL\",\"FORECAST\"]\n",
    "forecast_df = result\n",
    "forecast_df = forecast_df.round()\n",
    "forecast_df = forecast_df.fillna(0)\n",
    "for i in range(0, len(forecast_df)):\n",
    "    if forecast_df.FORECAST[i] <= 0:\n",
    "        forecast_df.FORECAST[i] = 0\n",
    "forecast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upc_list = []\n",
    "departmentname_list = []\n",
    "\n",
    "for i in range(0, 60):\n",
    "    upc_list.append(upc_code)\n",
    "    departmentname_list.append(departmentname)\n",
    "    \n",
    "details_df = pd.DataFrame({\n",
    "    \"upc_code\": upc_list,\n",
    "    \"departmentname\": departmentname_list\n",
    "})\n",
    "\n",
    "final_df = pd.concat((details_df, forecast_df), axis = 1)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(final_df.ACTUAL, label = \"Test Value\")\n",
    "plt.plot(final_df.FORECAST, label = \"Predicted Value\")\n",
    "plt.title(\"Actual v/s Forecast values\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save forecast file to storage bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"forecast.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the Predictions file on GCS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp -r forecast.csv gs://usc-demo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
